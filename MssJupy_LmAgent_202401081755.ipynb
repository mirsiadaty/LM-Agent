{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a951a39d-125f-4d81-b536-9c8edd2d4108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bebd44c-643e-4f43-a6d8-3f20a87c78c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "#\n",
    "# Agent with compositional reasoning\n",
    "# LLM: OpenAI GPT4 / Mixtral (local)\n",
    "# Tools: Google real-time Search, Math Calculator\n",
    "# MSS 20240106\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187bf4f3-0f12-4fc5-9d1c-5ff5429da404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1565576-0862-49db-b991-f43d84fcb4cc",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "## call in libs: Google Search, and OpenAI GPT4\n",
    "## define tools for agent to use\n",
    "## define the agent\n",
    "## assign task to agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7721410b-40ea-4466-b294-e31c62cdb180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee1bdfb0-8f4f-4152-a68f-5d59cd21a8d6",
   "metadata": {},
   "source": [
    "# call in libs: Google Search, and OpenAI GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af903bf0-63db-4d20-b3ae-1d3b765778b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Mon Jan  8 18:02:07 2024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from googleapiclient.discovery import build\n",
    "from py_expression_eval import Parser\n",
    "import re, time, os\n",
    "\n",
    "# MssJupy_Agent_202401081755.ipynb : use same sysprompt with gpt4\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "print( '99' ,time.asctime( time.localtime( time.time() ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac44515-a36f-4fe1-8023-3f6231450f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58fa1085-f8e9-441a-ba64-ea74e40b2a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Mon Jan  8 18:02:18 2024\n"
     ]
    }
   ],
   "source": [
    "## google api parms\n",
    "with open('/home/ghtw30s/5u5uu', 'r') as file:\n",
    "    gcx = file.read().rstrip()\n",
    "\n",
    "print( '99' ,time.asctime( time.localtime( time.time() ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09c8fc06-7aa5-4f69-8476-a16851668874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Mon Jan  8 18:02:34 2024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('/home/ghtw30s/96t77i', 'r') as file:\n",
    "    oaiapikey = file.read().rstrip()\n",
    "\n",
    "\n",
    "print( '99' ,time.asctime( time.localtime( time.time() ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04f60280-5929-4de5-b91a-0c995af2d4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Mon Jan  8 18:02:53 2024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "client = OpenAI(api_key=oaiapikey)\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = gcx\n",
    "os.environ[\"GOOGLE_API_KEY\"] = gkey\n",
    "\n",
    "\n",
    "print( '99' ,time.asctime( time.localtime( time.time() ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d5a21-9bdb-41f3-8aff-298afdd2beea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6649e76b-de7b-4f52-bbf1-27f292a4ed4d",
   "metadata": {},
   "source": [
    "# force to use particular GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b53cede-a3ef-477e-b1f9-356d23ac7725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBGpuToUse 0\n",
      "Mon Jan  8 18:03:58 2024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### force to use particular GPU\n",
    "\n",
    "GLOBGpuToUse =\"1\"\n",
    "# 1 being used by DemoFusion\n",
    "GLOBGpuToUse =\"0\"\n",
    "\n",
    "\n",
    "\n",
    "print('GLOBGpuToUse' ,GLOBGpuToUse)\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GLOBGpuToUse\n",
    "\n",
    "\n",
    "print(time.asctime( time.localtime( time.time() ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c94711-a058-44a2-b8b8-1a4ed6ef8ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4208bd3-9011-4fdc-a834-245518e3ce6f",
   "metadata": {},
   "source": [
    "# garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55e1408d-cc8c-4747-af1c-59690a9caf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan  8 18:04:03 2024\n",
      "Mon Jan  8 18:04:03 2024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, gc, re, warnings\n",
    "# Garbage Collection\n",
    "\n",
    "print(time.asctime( time.localtime( time.time() ) ))\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "print(time.asctime( time.localtime( time.time() ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df2f7f-3aa0-4ad0-bce5-01353a2f7580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35c5ff0b-ea71-4b47-8276-96220d35e94d",
   "metadata": {},
   "source": [
    "# define tools for agent to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcfb5822-c97f-4db5-add1-17ed4593d21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Mon Jan  8 18:05:47 2024\n"
     ]
    }
   ],
   "source": [
    "#Google search engine\n",
    "def search(search_term):\n",
    "    search_result = \"\"\n",
    "    service = build(\"customsearch\", \"v1\", developerKey=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "    res = service.cse().list(q=search_term, cx=os.environ.get(\"GOOGLE_CSE_ID\"), num = 10).execute()\n",
    "    for result in res['items']:\n",
    "        search_result = search_result + result['snippet']\n",
    "    return search_result\n",
    "\n",
    "\n",
    "parser = Parser()\n",
    "def calculator(str):\n",
    "    return parser.parse(str).evaluate({})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# MssJupy_Agent_202401061636.ipynb : replace gpt4 with local mixtral.\n",
    "def calculator_rag_local(prompt):\n",
    "    Calc_rag_System_prompt = \"\"\"\n",
    "Answer the question marked up by <Question> and </Question>.\n",
    "Use the information provided in the context marked up by <Context> and </Context>.\n",
    "\"\"\"\n",
    "    #\n",
    "    Calc_System_prompt = \"\"\"\n",
    "Answer the following questions and obey the following commands as best you can.\n",
    "\n",
    "Try to estimate/calculate what the question is asking about, and respond with a number.\n",
    "\"\"\"\n",
    "    #    \n",
    "    # 1: IR\n",
    "    IRresponse = search(prompt)\n",
    "    \n",
    "    # 2: LLM\n",
    "    user_rag_prmpt = '<Question>'+prompt +\"</Question>\\n\\n<Context>\"+ IRresponse + '</Context>'\n",
    "    \n",
    "    \n",
    "    prompt11 = \"<s>[INST]\"+   Calc_rag_System_prompt +'\\n\\n'+ user_rag_prmpt   +\"\\n[/INST]\\n\"\n",
    "    \n",
    "    #\n",
    "    inputs34 = tokenizer101(prompt11, return_tensors=\"pt\")\n",
    "    inputs34 = inputs34.to('cuda')\n",
    "    outputs45 = model101.generate(**inputs34, max_new_tokens=9999, do_sample=False ,temperature=0.0)\n",
    "    response_text = tokenizer101.decode(outputs45[0], skip_special_tokens=True)\n",
    "    #\n",
    "    return response_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculator_rag(prompt):\n",
    "    Calc_rag_System_prompt = \"\"\"\n",
    "Answer the question marked up by <Question> and </Question>.\n",
    "Use the information provided in the context marked up by <Context> and </Context>.\n",
    "\"\"\"\n",
    "    #\n",
    "    Calc_System_prompt = \"\"\"\n",
    "Answer the following questions and obey the following commands as best you can.\n",
    "\n",
    "Try to estimate/calculate what the question is asking about, and respond with a number.\n",
    "\"\"\"\n",
    "    #    \n",
    "    # 1: IR\n",
    "    IRresponse = search(prompt)\n",
    "    #print('IRresponse' , IRresponse) # debug\n",
    "    \n",
    "    # 2: LLM\n",
    "    user_rag_prmpt = '<Question>'+prompt +\"</Question>\\n\\n<Context>\"+ IRresponse + '</Context>'\n",
    "    #print('user_rag_prmpt' , user_rag_prmpt) # debug\n",
    "    \n",
    "    messages = [\n",
    "        #{ \"role\": \"system\", \"content\": Calc_System_prompt },\n",
    "        { \"role\": \"system\", \"content\": Calc_rag_System_prompt },\n",
    "        { \"role\": \"user\", \"content\": user_rag_prmpt },\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages,\n",
    "            temperature=0, # Temperature: Controls randomness, higher values increase diversity.\n",
    "            max_tokens=1000,\n",
    "            top_p=1, # Top-p (nucleus): The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus.\n",
    "            # Top-k: Sample from the k most likely next tokens at each step. Lower k focuses on higher probability tokens.\n",
    "        )\n",
    "    response_text = response.choices[0].message.content\n",
    "    \n",
    "    \n",
    "    #print('----------------------------------------' , time.asctime(time.localtime(time.time())) )\n",
    "    ##print('* LLM response: {{{',response_text,'}}}')\n",
    "    #print('* calculator_rag response: {{{',response_text,'}}}')\n",
    "    \n",
    "    #\n",
    "    return response_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# MssJupy_Agent_202401061636.ipynb : replace gpt4 with local mixtral.\n",
    "'''\n",
    "def calculator_llm(prompt):\n",
    "    Calc_System_prompt = \"\"\"\n",
    "Answer the following questions and obey the following commands as best you can.\n",
    "\n",
    "Try to estimate/calculate what the question is asking about, and respond with a number.\n",
    "\"\"\"\n",
    "    #\n",
    "    messages = [\n",
    "        { \"role\": \"system\", \"content\": Calc_System_prompt },\n",
    "        { \"role\": \"user\", \"content\": prompt },\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages,\n",
    "            temperature=0, # Temperature: Controls randomness, higher values increase diversity.\n",
    "            max_tokens=1000,\n",
    "            top_p=1, # Top-p (nucleus): The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus.\n",
    "            # Top-k: Sample from the k most likely next tokens at each step. Lower k focuses on higher probability tokens.\n",
    "        )\n",
    "    response_text = response.choices[0].message.content\n",
    "    \n",
    "    print('----------------------------------------' , time.asctime(time.localtime(time.time())) )\n",
    "    print('* LLM response: {{{',response_text,'}}}')\n",
    "    return response_text\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "print( '99' ,time.asctime( time.localtime( time.time() ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1737b9-e92e-471c-abe4-409c897e4f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3678b40-cf55-430f-b65d-ec39e05780ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66f13c8a-2c37-466c-a240-932284b7dd81",
   "metadata": {},
   "source": [
    "# define LLM behavior: prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd93e4e4-a987-4499-95f3-2acd60319d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is Mon Jan  8 18:06:02 2024 \n",
      "Answer the following questions and obey the following commands as best you can.\n",
      "\n",
      "You have access to the following tools:\n",
      "\n",
      "Search: useful for when you need to answer questions about current events. You should ask targeted questions.\n",
      "Calculator: Useful for when you need to answer questions that require mathematical calculations or quantitative estimations.\n",
      "Response To Human: When you need to respond to the human you are talking to.\n",
      "\n",
      "You will receive a message from the human, then you should start a loop and do one of four Options:\n",
      "\n",
      "\n",
      "Option 1: Think about the subgoals for achieving the message from the human.\n",
      "Sometimes human's question is a multi-hop question, and might need to be decomposed into two or more simple questions.\n",
      "You then seek answer per each simpler question, and when all the simpler questions are answered then compose the answer to the initial complex multi-hop question.\n",
      "The following are four examples marked up by <ComposionalReasoning> and </ComposionalReasoning> for how to decompose complex questions into sets of simpler ones:\n",
      "\n",
      "<ComposionalReasoning>\n",
      "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How old was Muhammad Ali when he died?\n",
      "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
      "Follow up: How old was Alan Turing when he died?\n",
      "Intermediate answer: Alan Turing was 41 years old when he died.\n",
      "So the final answer is: Muhammad Ali \n",
      "\n",
      "Question: When was the founder of craigslist born?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the founder of craigslist?\n",
      "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
      "Follow up: When was Craig Newmark born?\n",
      "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
      "So the final answer is: December 6, 1952\n",
      "\n",
      "Question: Who was the maternal grandfather of George Washington?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball \n",
      "\n",
      "Question: Are both the directors of Jaws and Casino Royale from the same country? \n",
      "Are follow up questions needed here: Yes. \n",
      "Follow up: Who is the director of Jaws? \n",
      "Intermediate Answer: The director of Jaws is Steven Spielberg. \n",
      "Follow up: Where is Steven Spielberg from? \n",
      "Intermediate Answer: The United States. \n",
      "Follow up: Who is the director of Casino Royale? \n",
      "Intermediate Answer: The director of Casino Royale is Martin Campbell. \n",
      "Follow up: Where is Martin Campbell from? \n",
      "Intermediate Answer: New Zealand. \n",
      "So the final answer is: No\n",
      "</ComposionalReasoning>\n",
      "\n",
      "\n",
      "Option 2: You use a tool to answer the question.\n",
      "For this, you should use the following format:\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search, Calculator]\n",
      "Action Input: \"the input to the action, to be sent to the tool\"\n",
      "\n",
      "After this, the human will respond with an observation, and you will continue.\n",
      "\n",
      "\n",
      "Option 3: Reflect on how you arrived at the answer and whether the answer is correct.\n",
      "\n",
      "\n",
      "Option 4: You respond to the human.\n",
      "For this, you should use the following format:\n",
      "Action: Response To Human\n",
      "Action Input: \"your response to the human, summarizing what you did and what you learned\"\n",
      "\n",
      "\n",
      "Begin!\n",
      "99 Mon Jan  8 18:06:02 2024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# MssJupy_Agent_202401061330.ipynb : agent with compositional reasoning.\n",
    "\n",
    "# also, it may help agent to know today's date explicitly.\n",
    "    # MSS OBS 20240106: we see agent's interpretation of \"the reigning men's U.S. Open champion\" chnaged from from 2022 to 2023.\n",
    "    # Then it might be good to explicitly declare today in the system promot!\n",
    "todayis = time.asctime( time.localtime( time.time() ) )\n",
    "\n",
    "\n",
    "\n",
    "# MssJupy_Agent_202401061636.ipynb : replace gpt4 with local mixtral.\n",
    "# we removed newlines at left and rightmost of System_prompt_selfask\n",
    "\n",
    "\n",
    "# MssJupy_Agent_202401081740.ipynb : edit llm system prompt: 1.break down given task, 2.self reflect (cove: chain of verification).\n",
    "\n",
    "System_prompt_selfask = 'Today is '+todayis +\"\"\" \n",
    "Answer the following questions and obey the following commands as best you can.\n",
    "\n",
    "You have access to the following tools:\n",
    "\n",
    "Search: useful for when you need to answer questions about current events. You should ask targeted questions.\n",
    "Calculator: Useful for when you need to answer questions that require mathematical calculations or quantitative estimations.\n",
    "Response To Human: When you need to respond to the human you are talking to.\n",
    "\n",
    "You will receive a message from the human, then you should start a loop and do one of four Options:\n",
    "\n",
    "\n",
    "Option 1: Think about the subgoals for achieving the message from the human.\n",
    "Sometimes human's question is a multi-hop question, and might need to be decomposed into two or more simple questions.\n",
    "You then seek answer per each simpler question, and when all the simpler questions are answered then compose the answer to the initial complex multi-hop question.\n",
    "The following are four examples marked up by <ComposionalReasoning> and </ComposionalReasoning> for how to decompose complex questions into sets of simpler ones:\n",
    "\n",
    "<ComposionalReasoning>\n",
    "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: How old was Muhammad Ali when he died?\n",
    "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
    "Follow up: How old was Alan Turing when he died?\n",
    "Intermediate answer: Alan Turing was 41 years old when he died.\n",
    "So the final answer is: Muhammad Ali \n",
    "\n",
    "Question: When was the founder of craigslist born?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the founder of craigslist?\n",
    "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
    "Follow up: When was Craig Newmark born?\n",
    "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
    "So the final answer is: December 6, 1952\n",
    "\n",
    "Question: Who was the maternal grandfather of George Washington?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the mother of George Washington?\n",
    "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
    "Follow up: Who was the father of Mary Ball Washington?\n",
    "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
    "So the final answer is: Joseph Ball \n",
    "\n",
    "Question: Are both the directors of Jaws and Casino Royale from the same country? \n",
    "Are follow up questions needed here: Yes. \n",
    "Follow up: Who is the director of Jaws? \n",
    "Intermediate Answer: The director of Jaws is Steven Spielberg. \n",
    "Follow up: Where is Steven Spielberg from? \n",
    "Intermediate Answer: The United States. \n",
    "Follow up: Who is the director of Casino Royale? \n",
    "Intermediate Answer: The director of Casino Royale is Martin Campbell. \n",
    "Follow up: Where is Martin Campbell from? \n",
    "Intermediate Answer: New Zealand. \n",
    "So the final answer is: No\n",
    "</ComposionalReasoning>\n",
    "\n",
    "\n",
    "Option 2: You use a tool to answer the question.\n",
    "For this, you should use the following format:\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [Search, Calculator]\n",
    "Action Input: \"the input to the action, to be sent to the tool\"\n",
    "\n",
    "After this, the human will respond with an observation, and you will continue.\n",
    "\n",
    "\n",
    "Option 3: Reflect on how you arrived at the answer and whether the answer is correct.\n",
    "\n",
    "\n",
    "Option 4: You respond to the human.\n",
    "For this, you should use the following format:\n",
    "Action: Response To Human\n",
    "Action Input: \"your response to the human, summarizing what you did and what you learned\"\n",
    "\n",
    "\n",
    "Begin!\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(System_prompt_selfask)\n",
    "\n",
    "print( '99' ,time.asctime( time.localtime( time.time() ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6477d866-f28a-461f-8152-d83bb163da0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c393ccf-8e63-451d-b43b-0f2a91d8f0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6262745f-0e05-4943-841d-52e07d26d87e",
   "metadata": {},
   "source": [
    "# define the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61f14ec5-6012-4b9e-b3b5-349fc1212aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Mon Jan  8 18:07:24 2024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# MssJupy_Agent_202401081755.ipynb : use same sysprompt with gpt4\n",
    "\n",
    "def agent_compositional(prompt):\n",
    "    #\n",
    "    IterCounter = 0\n",
    "    \n",
    "    #\n",
    "    messages = [\n",
    "        { \"role\": \"system\", \"content\": System_prompt_selfask },\n",
    "        { \"role\": \"user\", \"content\": prompt },\n",
    "    ]\n",
    "    def extract_action_and_input(text):\n",
    "          action_pattern = r\"Action: (.+?)\\n\"\n",
    "        \n",
    "          input_pattern = r\"Action Input: \\\"(.+?)\\\"\"\n",
    "        \n",
    "          action = re.findall(action_pattern, text)\n",
    "          \n",
    "          action_input = re.findall(input_pattern, text, re.DOTALL)\n",
    "          \n",
    "          return action, action_input\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        print('\\n======================================================================'  )\n",
    "        print('IterCounter' ,IterCounter)\n",
    "        \n",
    "        print('* going to LLM...')\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages,\n",
    "            temperature=0, # Temperature: Controls randomness, higher values increase diversity.\n",
    "            max_tokens=1000,\n",
    "            top_p=1, # Top-p (nucleus): The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus.\n",
    "            # Top-k: Sample from the k most likely next tokens at each step. Lower k focuses on higher probability tokens.\n",
    "        )\n",
    "        response_text = response.choices[0].message.content\n",
    "        \n",
    "        print('----------------------------------------' , time.asctime(time.localtime(time.time())) )\n",
    "        #\n",
    "        print('{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{')\n",
    "        print('* LLM response: \\n' + response_text , '')\n",
    "        print('}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}')\n",
    "        \n",
    "        \n",
    "        #time.sleep(30)\n",
    "        time.sleep(0)\n",
    "        \n",
    "        action, action_input = extract_action_and_input(response_text)\n",
    "        \n",
    "        # debug\n",
    "        #print('DBG', 'action' ,action)\n",
    "        #print('DBG', 'action_input' ,action_input)\n",
    "        \n",
    "        if action[-1] == \"Search\":\n",
    "            tool = search\n",
    "            \n",
    "        elif action[-1] == \"Calculator\":\n",
    "            #tool = calculator\n",
    "            tool = calculator_rag\n",
    "            \n",
    "        elif action[-1] == \"Response To Human\":\n",
    "            #print(f\"Response: {action_input[-1]}\")\n",
    "            #print('----------------------------------------')\n",
    "            print('========================================' , time.asctime(time.localtime(time.time())) )\n",
    "            print(f\"* Final: {action_input[-1]}\")\n",
    "            print('----------------------------------------')\n",
    "            break\n",
    "        \n",
    "        print('----------------------------------------' , time.asctime(time.localtime(time.time())) )\n",
    "        print('* TOOL chosen by the agent:' ,tool)\n",
    "        observation = tool(action_input[-1])\n",
    "        \n",
    "        # in agent lingo, the response from a tool is called \"observation\"\n",
    "        print('----------------------------------------', time.asctime(time.localtime(time.time())) )\n",
    "        print(\"* Results from the tool: {{{\", observation,'}}}')\n",
    "        \n",
    "        # mss: the llm response goes to SystemPrmopt, and the tool response goes to the UserPrompt\n",
    "        messages.extend([\n",
    "            { \"role\": \"system\", \"content\": response_text },\n",
    "            { \"role\": \"user\", \"content\": f\"Observation: {observation}\" },\n",
    "            ])\n",
    "        \n",
    "        print('----------------------------------------', time.asctime(time.localtime(time.time())) )\n",
    "        # we convert to list of lists, then we flatten\n",
    "        str6 = [ [key+\":\"+val for key, val in dct4.items()] for dct4 in messages]\n",
    "        from itertools import chain\n",
    "        str6f = list(chain.from_iterable(str6))\n",
    "        mem44 = \"\\n----------------\\n\".join(str6f)\n",
    "        print('((((((((((((((((((((((((((((((((((((((((((((((((')\n",
    "        print('* memory: \\n' + mem44 , '\\n')\n",
    "        print('))))))))))))))))))))))))))))))))))))))))))))))))')\n",
    "        #\n",
    "        IterCounter +=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def agent_compositional_local(prompt, System_prompt_selfask):\n",
    "    #\n",
    "    IterCounter = 0\n",
    "    \n",
    "    prompt11 =  \"<s> [INST] \"+   System_prompt_selfask +'\\n\\n'+ prompt   +\"\\n[/INST]\\n\"\n",
    "    \n",
    "    \n",
    "    def extract_action_and_input(text):\n",
    "          action_pattern = r\"Action: (.+?)\\n\"\n",
    "        \n",
    "          input_pattern = r\"Action Input: (.*)\"\n",
    "          \n",
    "          action = re.findall(action_pattern, text)\n",
    "          \n",
    "          action_input = re.findall(input_pattern, text)\n",
    "          \n",
    "          return action, action_input\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        print('\\n======================================================================'  )\n",
    "        print('IterCounter' ,IterCounter)\n",
    "        \n",
    "        print('* going to LLM...')\n",
    "        \n",
    "        # DEBUG\n",
    "        print('prompt11=[[' , prompt11, ']]')\n",
    "        \n",
    "        #\n",
    "        inputs34 = tokenizer101(prompt11, return_tensors=\"pt\")\n",
    "        inputs34 = inputs34.to('cuda')\n",
    "        outputs45 = model101.generate(**inputs34, max_new_tokens=9999, do_sample=False ,temperature=0.0)\n",
    "        response_text = tokenizer101.decode(outputs45[0], skip_special_tokens=True)\n",
    "        # MSS => we HAVE TO SKIP special tokens in llm response, so that we insert <s> and </s> in correct locations in the cumulative prompt!\n",
    "        \n",
    "        \n",
    "        print('----------------------------------------' , time.asctime(time.localtime(time.time())) )\n",
    "        #\n",
    "        print('{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{')\n",
    "        print('* LLM response: \\n' + response_text , '')\n",
    "        print('}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}')\n",
    "        \n",
    "        \n",
    "        #time.sleep(30)\n",
    "        time.sleep(0)\n",
    "        \n",
    "        action, action_input = extract_action_and_input(response_text)\n",
    "        \n",
    "        if action[-1] == \"Search\":\n",
    "            tool = search\n",
    "            \n",
    "        elif action[-1] == \"Calculator\":\n",
    "            #tool = calculator\n",
    "            tool = calculator_rag_local\n",
    "            \n",
    "            \n",
    "        elif action[-1] == \"Response To Human\":\n",
    "            #print(f\"Response: {action_input[-1]}\")\n",
    "            #print('----------------------------------------')\n",
    "            print('========================================' , time.asctime(time.localtime(time.time())) )\n",
    "            print(f\"* Final: {action_input[-1]}\")\n",
    "            print('----------------------------------------')\n",
    "            break\n",
    "        \n",
    "        print('----------------------------------------' , time.asctime(time.localtime(time.time())) )\n",
    "        print('* TOOL chosen by the agent:' ,tool)\n",
    "        observation = tool(action_input[-1])\n",
    "        \n",
    "        # in agent lingo, the response from a tool is called \"observation\"\n",
    "        print('----------------------------------------', time.asctime(time.localtime(time.time())) )\n",
    "        print(\"* Results from the tool: {{{\", observation,'}}}')\n",
    "        \n",
    "        \n",
    "        \n",
    "        System_prompt_selfask = response_text\n",
    "        prompt = observation\n",
    "        # remove any leftmost space first\n",
    "        System_prompt_selfask = System_prompt_selfask.lstrip()\n",
    "        prompt11 = \"<s> \"+   System_prompt_selfask +' </s> '       + '[INST] '+ prompt   +\"\\n[/INST]\\n\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('----------------------------------------', time.asctime(time.localtime(time.time())) )\n",
    "        #\n",
    "        IterCounter +=1\n",
    "        \n",
    "\n",
    "\n",
    "print( '99' ,time.asctime( time.localtime( time.time() ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b298b-2366-4dcb-8ad4-88d7350c7a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7170ca54-23ef-45a9-8851-bd704c7c7169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53570fba-f6a4-41dd-9a89-df66d3092f9a",
   "metadata": {},
   "source": [
    "# assign task to agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "881eda1e-53f6-41d0-9a83-380732b03f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Mon Jan  8 18:13:06 2024\n",
      "----------------------------------------\n",
      "user_request: how many days till the next solar eclipse\n",
      "\n",
      "======================================================================\n",
      "IterCounter 0\n",
      "* going to LLM...\n",
      "---------------------------------------- Mon Jan  8 18:13:11 2024\n",
      "{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{\n",
      "* LLM response: \n",
      "Thought: To answer this question, I need to find out the date of the next solar eclipse and then calculate the difference between that date and today's date. \n",
      "Action: Search\n",
      "Action Input: \"Next solar eclipse date\" \n",
      "}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}\n",
      "---------------------------------------- Mon Jan  8 18:13:11 2024\n",
      "* TOOL chosen by the agent: <function search at 0x7efcd462c670>\n",
      "---------------------------------------- Mon Jan  8 18:13:12 2024\n",
      "* Results from the tool: {{{ Otherwise all partial solar eclipses need approved filters. For approved filters, look for a certification of International Standard ISO 12312-2. The next solar ...The next annular eclipse will be October 2041. It is never safe to look at the sun during an annular eclipse without special purpose solar filters. Eclipse ...On April 8, 2024, a total solar eclipse will cross North America, passing over Mexico, the United States, and Canada. A total solar eclipse happens when the ...Featured Eclipses in Coming Years · 1Apr 8, 2024Total Solar Eclipse · 2Oct 2, 2024Annular Solar Eclipse · 3Feb 17, 2026Annular Solar Eclipse · 4Aug 12, 2026Total ...Future Eclipses · Get Ready for These Upcoming Eclipses in the United States! · Annular Solar Eclipse - October 14, 2023 · Total Solar Eclipse - April 8, 2024.6 days ago ... The next solar eclipse will be on April 8, 2024. ... Jump to: Types of solar eclipse; Upcoming solar eclipses; Total solar eclipse: April 8, 2024 ...Aug 27, 2016 ... NASA's Solar Eclipse Bulletins were special publications issued periodically that focused on major upcoming solar eclipses. Each bulletin ...Apr 7, 2023 ... Just one year from now, a total solar eclipse will sweep across North America. The eclipse will slice a diagonal line across 13 states in ...Our list of upcoming LIVE streams of solar and lunar eclipses. Great American Eclipse 2023. Annular solar eclipse visible in parts of the US, as well as several ...On this date, people within a 124-mile-wide band in the state of Ohio will experience a total solar eclipse. Areas in Ohio that are outside the path of ... }}}\n",
      "---------------------------------------- Mon Jan  8 18:13:12 2024\n",
      "((((((((((((((((((((((((((((((((((((((((((((((((\n",
      "* memory: \n",
      "role:system\n",
      "----------------\n",
      "content:Today is Mon Jan  8 18:06:02 2024 \n",
      "Answer the following questions and obey the following commands as best you can.\n",
      "\n",
      "You have access to the following tools:\n",
      "\n",
      "Search: useful for when you need to answer questions about current events. You should ask targeted questions.\n",
      "Calculator: Useful for when you need to answer questions that require mathematical calculations or quantitative estimations.\n",
      "Response To Human: When you need to respond to the human you are talking to.\n",
      "\n",
      "You will receive a message from the human, then you should start a loop and do one of four Options:\n",
      "\n",
      "\n",
      "Option 1: Think about the subgoals for achieving the message from the human.\n",
      "Sometimes human's question is a multi-hop question, and might need to be decomposed into two or more simple questions.\n",
      "You then seek answer per each simpler question, and when all the simpler questions are answered then compose the answer to the initial complex multi-hop question.\n",
      "The following are four examples marked up by <ComposionalReasoning> and </ComposionalReasoning> for how to decompose complex questions into sets of simpler ones:\n",
      "\n",
      "<ComposionalReasoning>\n",
      "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How old was Muhammad Ali when he died?\n",
      "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
      "Follow up: How old was Alan Turing when he died?\n",
      "Intermediate answer: Alan Turing was 41 years old when he died.\n",
      "So the final answer is: Muhammad Ali \n",
      "\n",
      "Question: When was the founder of craigslist born?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the founder of craigslist?\n",
      "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
      "Follow up: When was Craig Newmark born?\n",
      "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
      "So the final answer is: December 6, 1952\n",
      "\n",
      "Question: Who was the maternal grandfather of George Washington?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball \n",
      "\n",
      "Question: Are both the directors of Jaws and Casino Royale from the same country? \n",
      "Are follow up questions needed here: Yes. \n",
      "Follow up: Who is the director of Jaws? \n",
      "Intermediate Answer: The director of Jaws is Steven Spielberg. \n",
      "Follow up: Where is Steven Spielberg from? \n",
      "Intermediate Answer: The United States. \n",
      "Follow up: Who is the director of Casino Royale? \n",
      "Intermediate Answer: The director of Casino Royale is Martin Campbell. \n",
      "Follow up: Where is Martin Campbell from? \n",
      "Intermediate Answer: New Zealand. \n",
      "So the final answer is: No\n",
      "</ComposionalReasoning>\n",
      "\n",
      "\n",
      "Option 2: You use a tool to answer the question.\n",
      "For this, you should use the following format:\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search, Calculator]\n",
      "Action Input: \"the input to the action, to be sent to the tool\"\n",
      "\n",
      "After this, the human will respond with an observation, and you will continue.\n",
      "\n",
      "\n",
      "Option 3: Reflect on how you arrived at the answer and whether the answer is correct.\n",
      "\n",
      "\n",
      "Option 4: You respond to the human.\n",
      "For this, you should use the following format:\n",
      "Action: Response To Human\n",
      "Action Input: \"your response to the human, summarizing what you did and what you learned\"\n",
      "\n",
      "\n",
      "Begin!\n",
      "----------------\n",
      "role:user\n",
      "----------------\n",
      "content:how many days till the next solar eclipse\n",
      "----------------\n",
      "role:system\n",
      "----------------\n",
      "content:Thought: To answer this question, I need to find out the date of the next solar eclipse and then calculate the difference between that date and today's date. \n",
      "Action: Search\n",
      "Action Input: \"Next solar eclipse date\"\n",
      "----------------\n",
      "role:user\n",
      "----------------\n",
      "content:Observation: Otherwise all partial solar eclipses need approved filters. For approved filters, look for a certification of International Standard ISO 12312-2. The next solar ...The next annular eclipse will be October 2041. It is never safe to look at the sun during an annular eclipse without special purpose solar filters. Eclipse ...On April 8, 2024, a total solar eclipse will cross North America, passing over Mexico, the United States, and Canada. A total solar eclipse happens when the ...Featured Eclipses in Coming Years · 1Apr 8, 2024Total Solar Eclipse · 2Oct 2, 2024Annular Solar Eclipse · 3Feb 17, 2026Annular Solar Eclipse · 4Aug 12, 2026Total ...Future Eclipses · Get Ready for These Upcoming Eclipses in the United States! · Annular Solar Eclipse - October 14, 2023 · Total Solar Eclipse - April 8, 2024.6 days ago ... The next solar eclipse will be on April 8, 2024. ... Jump to: Types of solar eclipse; Upcoming solar eclipses; Total solar eclipse: April 8, 2024 ...Aug 27, 2016 ... NASA's Solar Eclipse Bulletins were special publications issued periodically that focused on major upcoming solar eclipses. Each bulletin ...Apr 7, 2023 ... Just one year from now, a total solar eclipse will sweep across North America. The eclipse will slice a diagonal line across 13 states in ...Our list of upcoming LIVE streams of solar and lunar eclipses. Great American Eclipse 2023. Annular solar eclipse visible in parts of the US, as well as several ...On this date, people within a 124-mile-wide band in the state of Ohio will experience a total solar eclipse. Areas in Ohio that are outside the path of ... \n",
      "\n",
      "))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "\n",
      "======================================================================\n",
      "IterCounter 1\n",
      "* going to LLM...\n",
      "---------------------------------------- Mon Jan  8 18:13:15 2024\n",
      "{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{\n",
      "* LLM response: \n",
      "Thought: The next solar eclipse will be on April 8, 2024. Now I need to calculate the number of days between today's date (January 8, 2024) and the date of the next solar eclipse.\n",
      "Action: Calculator\n",
      "Action Input: \"Calculate the number of days between January 8, 2024 and April 8, 2024\" \n",
      "}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}\n",
      "---------------------------------------- Mon Jan  8 18:13:15 2024\n",
      "* TOOL chosen by the agent: <function calculator_rag at 0x7efcd46063b0>\n",
      "---------------------------------------- Mon Jan  8 18:13:17 2024\n",
      "* Results from the tool: {{{ The number of days between January 8, 2024 and April 8, 2024 is 90 days. }}}\n",
      "---------------------------------------- Mon Jan  8 18:13:17 2024\n",
      "((((((((((((((((((((((((((((((((((((((((((((((((\n",
      "* memory: \n",
      "role:system\n",
      "----------------\n",
      "content:Today is Mon Jan  8 18:06:02 2024 \n",
      "Answer the following questions and obey the following commands as best you can.\n",
      "\n",
      "You have access to the following tools:\n",
      "\n",
      "Search: useful for when you need to answer questions about current events. You should ask targeted questions.\n",
      "Calculator: Useful for when you need to answer questions that require mathematical calculations or quantitative estimations.\n",
      "Response To Human: When you need to respond to the human you are talking to.\n",
      "\n",
      "You will receive a message from the human, then you should start a loop and do one of four Options:\n",
      "\n",
      "\n",
      "Option 1: Think about the subgoals for achieving the message from the human.\n",
      "Sometimes human's question is a multi-hop question, and might need to be decomposed into two or more simple questions.\n",
      "You then seek answer per each simpler question, and when all the simpler questions are answered then compose the answer to the initial complex multi-hop question.\n",
      "The following are four examples marked up by <ComposionalReasoning> and </ComposionalReasoning> for how to decompose complex questions into sets of simpler ones:\n",
      "\n",
      "<ComposionalReasoning>\n",
      "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How old was Muhammad Ali when he died?\n",
      "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
      "Follow up: How old was Alan Turing when he died?\n",
      "Intermediate answer: Alan Turing was 41 years old when he died.\n",
      "So the final answer is: Muhammad Ali \n",
      "\n",
      "Question: When was the founder of craigslist born?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the founder of craigslist?\n",
      "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
      "Follow up: When was Craig Newmark born?\n",
      "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
      "So the final answer is: December 6, 1952\n",
      "\n",
      "Question: Who was the maternal grandfather of George Washington?\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball \n",
      "\n",
      "Question: Are both the directors of Jaws and Casino Royale from the same country? \n",
      "Are follow up questions needed here: Yes. \n",
      "Follow up: Who is the director of Jaws? \n",
      "Intermediate Answer: The director of Jaws is Steven Spielberg. \n",
      "Follow up: Where is Steven Spielberg from? \n",
      "Intermediate Answer: The United States. \n",
      "Follow up: Who is the director of Casino Royale? \n",
      "Intermediate Answer: The director of Casino Royale is Martin Campbell. \n",
      "Follow up: Where is Martin Campbell from? \n",
      "Intermediate Answer: New Zealand. \n",
      "So the final answer is: No\n",
      "</ComposionalReasoning>\n",
      "\n",
      "\n",
      "Option 2: You use a tool to answer the question.\n",
      "For this, you should use the following format:\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search, Calculator]\n",
      "Action Input: \"the input to the action, to be sent to the tool\"\n",
      "\n",
      "After this, the human will respond with an observation, and you will continue.\n",
      "\n",
      "\n",
      "Option 3: Reflect on how you arrived at the answer and whether the answer is correct.\n",
      "\n",
      "\n",
      "Option 4: You respond to the human.\n",
      "For this, you should use the following format:\n",
      "Action: Response To Human\n",
      "Action Input: \"your response to the human, summarizing what you did and what you learned\"\n",
      "\n",
      "\n",
      "Begin!\n",
      "----------------\n",
      "role:user\n",
      "----------------\n",
      "content:how many days till the next solar eclipse\n",
      "----------------\n",
      "role:system\n",
      "----------------\n",
      "content:Thought: To answer this question, I need to find out the date of the next solar eclipse and then calculate the difference between that date and today's date. \n",
      "Action: Search\n",
      "Action Input: \"Next solar eclipse date\"\n",
      "----------------\n",
      "role:user\n",
      "----------------\n",
      "content:Observation: Otherwise all partial solar eclipses need approved filters. For approved filters, look for a certification of International Standard ISO 12312-2. The next solar ...The next annular eclipse will be October 2041. It is never safe to look at the sun during an annular eclipse without special purpose solar filters. Eclipse ...On April 8, 2024, a total solar eclipse will cross North America, passing over Mexico, the United States, and Canada. A total solar eclipse happens when the ...Featured Eclipses in Coming Years · 1Apr 8, 2024Total Solar Eclipse · 2Oct 2, 2024Annular Solar Eclipse · 3Feb 17, 2026Annular Solar Eclipse · 4Aug 12, 2026Total ...Future Eclipses · Get Ready for These Upcoming Eclipses in the United States! · Annular Solar Eclipse - October 14, 2023 · Total Solar Eclipse - April 8, 2024.6 days ago ... The next solar eclipse will be on April 8, 2024. ... Jump to: Types of solar eclipse; Upcoming solar eclipses; Total solar eclipse: April 8, 2024 ...Aug 27, 2016 ... NASA's Solar Eclipse Bulletins were special publications issued periodically that focused on major upcoming solar eclipses. Each bulletin ...Apr 7, 2023 ... Just one year from now, a total solar eclipse will sweep across North America. The eclipse will slice a diagonal line across 13 states in ...Our list of upcoming LIVE streams of solar and lunar eclipses. Great American Eclipse 2023. Annular solar eclipse visible in parts of the US, as well as several ...On this date, people within a 124-mile-wide band in the state of Ohio will experience a total solar eclipse. Areas in Ohio that are outside the path of ...\n",
      "----------------\n",
      "role:system\n",
      "----------------\n",
      "content:Thought: The next solar eclipse will be on April 8, 2024. Now I need to calculate the number of days between today's date (January 8, 2024) and the date of the next solar eclipse.\n",
      "Action: Calculator\n",
      "Action Input: \"Calculate the number of days between January 8, 2024 and April 8, 2024\"\n",
      "----------------\n",
      "role:user\n",
      "----------------\n",
      "content:Observation: The number of days between January 8, 2024 and April 8, 2024 is 90 days. \n",
      "\n",
      "))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "\n",
      "======================================================================\n",
      "IterCounter 2\n",
      "* going to LLM...\n",
      "---------------------------------------- Mon Jan  8 18:13:20 2024\n",
      "{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{\n",
      "* LLM response: \n",
      "Thought: Now that I have calculated the number of days until the next solar eclipse, I can provide the answer to the human.\n",
      "Action: Response To Human\n",
      "Action Input: \"The next solar eclipse will occur in 90 days, on April 8, 2024.\" \n",
      "}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}\n",
      "======================================== Mon Jan  8 18:13:20 2024\n",
      "* Final: The next solar eclipse will occur in 90 days, on April 8, 2024.\n",
      "----------------------------------------\n",
      "FINAL: Took 14.088350772857666 seconds to run end-to-end.\n",
      "99 Mon Jan  8 18:13:20 2024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_request = \"how many days till the next solar eclipse\"\n",
    "#import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "startt = time.time()\n",
    "print( '11' ,time.asctime( time.localtime( time.time() ) ))\n",
    "\n",
    "print('----------------------------------------')\n",
    "print('user_request:' ,user_request)\n",
    "#print('----------------------------------------')\n",
    "\n",
    "#agent_compositional(user_request)\n",
    "#agent_compositional_local(user_request, System_prompt_selfask)\n",
    "agent_compositional(user_request)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "endt = time.time()\n",
    "print(\"FINAL: Took {} seconds to run end-to-end.\".format(endt - startt ))\n",
    "\n",
    "print( '99' ,time.asctime( time.localtime( time.time() ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3680b9ab-70ae-4178-9afa-2c609299b99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virenv20231122j",
   "language": "python",
   "name": "virenv20231122j"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
